{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f24d3f-6e1d-491b-9c10-dea31ff3f886",
   "metadata": {},
   "source": [
    "# QPM : Assignement 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402418c8-a79c-403c-af81-71e0c1e47b3c",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6534fea-3464-48c2-b382-b535317e5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1112274-0a6a-44b1-ae68-3656879115d8",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc053295-7bfb-4c1f-8fb7-6ee6655d8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_mean_return(df) :\n",
    "    return df.mean() * 12\n",
    "\n",
    "def annual_volatility(df) :\n",
    "    return df.std() * np.sqrt(12)\n",
    "\n",
    "def sharpe_ratio(df) :\n",
    "    return annual_mean_return(df) / annual_volatility(df)\n",
    "\n",
    "\n",
    "def get_multi_timeseries(list_underlying,startd,endd):\n",
    "    '''\n",
    "Function get_multi_timeseries:\n",
    "\n",
    "Returns the full time series of selected stocks metrics (Open, High, Low, Close, Adj Close, Volume, etc.)\n",
    "for a list of given stock tickers, over a specified time period and interval.\n",
    "\n",
    "Inputs:\n",
    "    - list_underlying: list of str ; tickers of the desired stocks.\n",
    "    - startd / endd: str ; start and end dates (inclusive) defining the time range to retrieve, in format \"YYYY-MM-DD\".\n",
    "    - metric: str or list-str ; name of the stock's metric(s) we want to select (close, open, high, ...).\n",
    "\n",
    "Output:\n",
    "    - DataFrame with:\n",
    "        - index: pandas Timestamps (dates in ascending order),\n",
    "        - columns: MultiIndex with first level = metrics (e.g., \"Close\"), \n",
    "                   second level = stock tickers.'''\n",
    "    return yf.download(list_underlying,start=startd,end=endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044bfc0a-c8ab-4050-a9ff-cb14ae7b9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_value = \"max\"\n",
    "interval_value = \"1d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043b0429-1483-4871-a4c2-42532f13c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/7kzpljcn0zl52pt8zpscgfj40000gn/T/ipykernel_3502/59220051.py:28: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  return yf.download(list_underlying,start=startd,end=endd)\n",
      "[*********************100%***********************]  6 of 6 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"AAPL\",\"MSFT\",\"AMZN\",\"NVDA\",\"TSLA\",\"META\"]\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "raw_market_data=get_multi_timeseries(tickers,start_date,end_date)\n",
    "close_price_data = raw_market_data.xs(\"Close\",axis = 1)\n",
    "#Change the index type from Timestamp to DateTimme\n",
    "close_price_data.index = pd.to_datetime(close_price_data.index, format = '%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77588ae-224e-40ed-9495-197022a02759",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weighting=[0.0710,0.0651,0.0324,0.0284,0.0187,0.0184] #Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd874ad-adb2-4765-91d0-32bf9e00a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the daily prices into monthly returns\n",
    "monthly_returns = close_price_data.resample('M').ffill().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b88c6ca4-fbde-4f94-835d-b567e5d55e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute excess returns assuming the riosk-free return is 0.\n",
    "excess_returns = monthly_returns - 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6d401b-7469-4eb8-b71a-0e243956bcd6",
   "metadata": {},
   "source": [
    "# Questions for Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08af3e6-743e-454a-83e8-1cad3eb25a3e",
   "metadata": {},
   "source": [
    "### Q6.1 Based on the sample data, compute the Markowitz portfolio weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a82c704e-fe26-430b-8833-c9a9d74e62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_variance(weights, cov_matrix):\n",
    "    \"\"\"\n",
    "    Computes the variance of a portfolio given asset weights and the covariance matrix.\n",
    "\n",
    "    Parameters:\n",
    "        weights (array-like): Portfolio weights.\n",
    "        cov_matrix (DataFrame or ndarray): Covariance matrix of asset returns.\n",
    "\n",
    "    Returns:\n",
    "        float: Portfolio variance (not annualized here).\n",
    "    \"\"\"\n",
    "    return weights.T @ cov_matrix @ weights\n",
    "\n",
    "def markowitz_weights(excess_returns):\n",
    "    \"\"\"\n",
    "    Computes the Markowitz minimum variance portfolio weights using excess returns.\n",
    "    The optimization minimizes portfolio variance under the constraint that the weights sum to 1.\n",
    "    \n",
    "    Parameters:\n",
    "        excess_returns (DataFrame): Excess returns (i.e., returns above the risk-free rate).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Optimal portfolio weights (sum to 1).\n",
    "    \"\"\"\n",
    "    # Step 1: Compute the covariance matrix of excess returns\n",
    "    cov_matrix = excess_returns.cov()\n",
    "    # Step 2: Compute expected excess returns (not used in this version, but available)\n",
    "    expected_returns = excess_returns.mean()\n",
    "    # Step 3: Define constraint: weights must sum to 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    # Step 4: Initial guess — equal weighting\n",
    "    init_guess = np.ones(len(expected_returns)) / len(expected_returns)\n",
    "    # Step 5: Optimization — minimize portfolio variance subject to constraint\n",
    "    opt_result = minimize(portfolio_variance, init_guess, args=(cov_matrix,), \n",
    "                      method='SLSQP', constraints=constraints)\n",
    "    # Step 6: Extract and return the optimal weights\n",
    "    markowitz_weights = opt_result.x\n",
    "    return markowitz_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86396cc9-da03-4e62-878b-4e24c9b50881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24986716, -0.01885959,  0.15487716,  0.80815194, -0.1301815 ,\n",
       "       -0.06385516])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markowitz_weights(excess_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a40157-6936-4b2d-bab7-9c7ff8f2be6b",
   "metadata": {},
   "source": [
    "### Q6.2 Then, using the market-capitalization weights, obtain the CAPM-implied expected returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d7333",
   "metadata": {},
   "source": [
    "The CAPM-implied expected returns are given by:\n",
    "\n",
    "$$\n",
    "\\mu_{\\text{CAPM}} = \\Sigma \\cdot w\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mu_{\\text{CAPM}}$ is the vector of implied expected excess returns under CAPM,  \n",
    "- $\\Sigma$ is the covariance matrix of asset excess returns,  \n",
    "- $w$ is the vector of market (index) portfolio weights.\n",
    "\n",
    "This corresponds to the idea that each asset's expected return is proportional to its **covariance with the market**, under the assumption that the market portfolio is mean-variance efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "032be66d-42fe-436f-8723-bcd10dff65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker\n",
      "AAPL    0.001248\n",
      "AMZN    0.001345\n",
      "META    0.001034\n",
      "MSFT    0.000881\n",
      "NVDA    0.001646\n",
      "TSLA    0.002079\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Compute the returns covariance matrix\n",
    "cov_matrix = excess_returns.cov()\n",
    "#Compute the CAPM implied returns\n",
    "capm_returns = cov_matrix @ np.array(index_weighting)\n",
    "print(capm_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266db6af-a688-4355-a18d-1a8a1e4a7a2b",
   "metadata": {},
   "source": [
    "### Q6.3 Then, specify the pick matrix P and the view vector q that captures the following views for each of the assets:\n",
    "#### AAPL: its absolute excess return is expected to be 10% per year.\n",
    "### MSFT: its absolute excess return is expected to be 5% per year.\n",
    "#### AMZN: no views\n",
    "#### NVDA will outperform TSLA by 2% per year.\n",
    "#### TSLA will underperform META by 1% per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04bcea5c-d30f-4ff2-a99f-67fc03eed0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick matrix\n",
    "P = np.array([\n",
    "    [1, 0, 0, 0, 0, 0],   # View on AAPL\n",
    "    [0, 0, 0, 1, 0, 0],   # View on MSFT\n",
    "    [0, 0, 0, 0, 1, -1],  # NVDA outperforms TSLA\n",
    "    [0, 0, -1, 0, 0, 1]   # TSLA underperforms META\n",
    "])\n",
    "#View vector.\n",
    "q = np.array([0.10, 0.05, 0.02, -0.01])\n",
    "Omega = 0.05*P@cov_matrix@P.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.4 Use these views to compute the conditional expected excess return and conditional covariance matrix of excess returns μBL and ΣBL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab9054",
   "metadata": {},
   "source": [
    "The Black-Litterman model adjusts expected returns and their uncertainty by blending market equilibrium (e.g., CAPM-implied) returns with investor views.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Black-Litterman Expected Returns (Conditional Mean)\n",
    "\n",
    "The adjusted expected returns under the Black-Litterman model are given by:\n",
    "\n",
    "$$\n",
    "\\mu_{\\text{BL}} = \\mu_{\\text{CAPM}} = \\mathbb{E}[R \\mid q]\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mu_{\\text{CAPM}}$ is the equilibrium (prior) return vector (e.g., from CAPM),\n",
    "- $q$ represents the investor’s views (mean of the subjective distribution),\n",
    "- $\\mathbb{E}[R \\mid q]$ is the posterior mean return vector after incorporating views.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Black-Litterman Posterior Covariance Matrix\n",
    "\n",
    "The posterior covariance matrix under the Black-Litterman model is:\n",
    "\n",
    "$$\n",
    "\\Sigma_{\\text{BL}} = (1 + \\tau) \\Sigma - \\tau^2 \\Sigma P^\\top \\left( P \\tau \\Sigma P^\\top + \\Omega \\right)^{-1} P \\Sigma\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\Sigma$ is the covariance matrix of returns,\n",
    "- $\\tau$ is a scalar representing the uncertainty in the prior estimates (typically small, e.g., 0.05),\n",
    "- $P$ is the matrix identifying which assets the views refer to,\n",
    "- $\\Omega$ is the covariance matrix of the views,\n",
    "- $\\Sigma_{\\text{BL}} = \\text{Var}[R \\mid q]$ is the posterior covariance matrix after views.\n",
    "\n",
    "---\n",
    "\n",
    "This model balances prior beliefs with investor confidence in new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a79c669e-b026-4150-bf6f-7693beee425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-Litterman Expected Return\n",
    "tau = 0.05\n",
    "Sigma=cov_matrix\n",
    "mu_BL =capm_returns # Conditional expected return (E[R|q])\n",
    "\n",
    "# Calculate V[R|q]\n",
    "middle_term = np.linalg.inv(P @ (tau * Sigma) @ P.T + Omega)\n",
    "V_BL = (1 + tau) * Sigma - (tau * Sigma @ P.T) @ middle_term @ (P @ (tau * Sigma)) #V[R|q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.5 Use μBL and ΣBL to compute the mean-variance weights and compare them with the weights from the CAPM and the weights based on sample moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio weights w_BL\n",
    "w_BL = np.linalg.inv(V_BL) @ mu_BL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f9da4cd-507e-4df1-9dcc-d21bde3c81d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00071638  0.0031      0.00158473 -0.00153546  0.00103573  0.00068906]\n"
     ]
    }
   ],
   "source": [
    "comparison = index_weighting - w_BL\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68be440-b1d0-49f3-98d3-e94d235632f2",
   "metadata": {},
   "source": [
    "#### We notice that the Black Litterman weights are very similar to the index weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empirical_methods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
